{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4c0620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import datgan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2106472",
   "metadata": {},
   "source": [
    "# DEFINE DATGAN VERSION\n",
    "\n",
    "### Set Foldername variable\n",
    "### Write ReadMe of run parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7764262",
   "metadata": {},
   "outputs": [],
   "source": [
    "DatGan_path = '/home/s212574/snap/snapd-desktop-integration/83/Documents/Thesis/MSc_PopSyn/Sigga_Luis/Data/'\n",
    "os.chdir(DatGan_path)\n",
    "\n",
    "# folder name\n",
    "folder_name = 'FolderName'          # Change this to the name of the folder you want to create\n",
    "ciDatGan_folder = 'ciDatGan'        # Create a folder for the ciDatGan data\n",
    "datGan_folder = 'DatGan'            # Create a folder for the DatGan data\n",
    "\n",
    "\n",
    "# Check if the folder doesn't exist, then create it\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "    print(f\"folder '{folder_name}' created successfully.\")\n",
    "else:\n",
    "    print(f\"folder '{folder_name}' already exists.\")\n",
    "    \n",
    "if not os.path.exists(folder_name + '/' + ciDatGan_folder):\n",
    "    os.makedirs(folder_name + '/' + ciDatGan_folder)\n",
    "    print(f\"folder '{ciDatGan_folder}' created successfully.\")\n",
    "else:\n",
    "    print(f\"folder '{folder_name}' already exists.\")\n",
    "\n",
    "if not os.path.exists(folder_name + '/' + datGan_folder):\n",
    "    os.makedirs(folder_name + '/' + datGan_folder)\n",
    "    print(f\"folder '{datGan_folder}' created successfully.\")\n",
    "else:\n",
    "    print(f\"folder '{folder_name}' already exists.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc392aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dtypes = {\n",
    "    'CarModelYear': 'category',\n",
    "    'Education': 'category',\n",
    "    'FamNumAdults': 'category',\n",
    "    'FamNumPers': 'category',\n",
    "    'FuelType': 'category',\n",
    "    'Gender': 'category',\n",
    "    'Handicap': 'category',\n",
    "    'HomeAdrZone': 'category',\n",
    "    'HousehCarOwnership': 'category',\n",
    "    'HousehNumAdults': 'category',\n",
    "    'HousehNumPers': 'category',\n",
    "    'HousehNumcars': 'category',\n",
    "    'HwDayspW': 'category',\n",
    "    'IncFamily2000': 'int64',\n",
    "    'IncRespondent2000': 'int64',\n",
    "    'KidsBetween0and4': 'category',\n",
    "    'KidsBetween0and15': 'category',\n",
    "    'MunicipalityDest': 'category',\n",
    "    'MunicipalityOrigin': 'category',\n",
    "    'PopSocio': 'category',\n",
    "    'PrimOccZone': 'category',\n",
    "    'RespAgeCorrect': 'int64',\n",
    "    'RespHasBicycle': 'category',\n",
    "    'RespHasRejsekort': 'category',\n",
    "    'RespIsmemCarshare': 'category',\n",
    "    'RespPrimOcc': 'category',\n",
    "    'ResphasDrivlic': 'category',\n",
    "    'Sector': 'category',\n",
    "    'WorkHourType': 'category',\n",
    "    'WorkHoursPw': 'float64',\n",
    "    'Year': 'category',\n",
    "    'HomeParkPoss': 'category',\n",
    "    'HousehAccomodation': 'category',\n",
    "    'HousehAccOwnorRent': 'category',\n",
    "    'PosInFamily': 'category',\n",
    "    'PrimModeDay': 'category',\n",
    "    'ModeChainTypeDay': 'category',\n",
    "    'RespHasSeasonticket': 'category'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df84f596",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(DatGan_path + folder_name)\n",
    "# File path where you want to save the dictionary as a JSON file\n",
    "file_path = 'df_dtypes.json'\n",
    "\n",
    "# Save the dictionary as a JSON file\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(df_dtypes, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45ae1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('simulationData_withNewCat.csv', sep=',',dtype=df_dtypes)\n",
    "df.drop(columns=['SessionId'], inplace=True)\n",
    "\n",
    "\n",
    "# Select numerical columns excluding categorical\n",
    "numerical_columns = df.select_dtypes(exclude='category').columns.tolist()\n",
    "\n",
    "# Calculate ranges for numerical columns\n",
    "ranges = {}\n",
    "for col in numerical_columns:\n",
    "    col_range = {\n",
    "        'min': df[col].min(),\n",
    "        'max': df[col].max(),\n",
    "        'range': np.ptp(df[col])  # Peak-to-Peak (max - min)\n",
    "    }\n",
    "    ranges[col] = col_range\n",
    "\n",
    "# Format and print ranges in rows\n",
    "for col, info in ranges.items():\n",
    "    print(f\"Column: {col}\")\n",
    "    print(f\"Min: {info['min']} | Max: {info['max']} | Range: {info['range']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a07fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info = {\n",
    "        'WorkHoursPw': {\n",
    "            'type': 'continuous',\n",
    "            'bounds': [0.0, 168.0],  # Min: 0.0 | Max: 168.0 | Range: 168.0\n",
    "            'discrete': False\n",
    "        },\n",
    "        'IncRespondent2000': {\n",
    "            'type': 'continuous',\n",
    "            'bounds': [0, 10000],  # Min: 0 | Max: 70640 | Range: 70640\n",
    "            'discrete': True\n",
    "        },\n",
    "        'IncFamily2000': {\n",
    "            'type': 'continuous',\n",
    "            'bounds': [0, 10000],  # Min: 0 | Max: 41358 | Range: 41358\n",
    "            'discrete': True\n",
    "        },\n",
    "        'RespAgeCorrect': {\n",
    "            'type': 'continuous',\n",
    "            'bounds': [5, 107],  # Min: 5 | Max: 107 | Range: 102\n",
    "            'discrete': True\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb2f506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the categorical columns, we can simply add them using a for loop\n",
    "for c in df.columns:\n",
    "    if c not in data_info.keys():\n",
    "        data_info[c] = {'type': 'categorical'}\n",
    "\n",
    "# Convert columns in df according to data_info dictionary\n",
    "for column, info in data_info.items():\n",
    "    col_type = info['type']\n",
    "        \n",
    "    if col_type == 'categorical':\n",
    "        df[column] = df[column].astype('category')  # Convert to categorical dtype\n",
    "\n",
    "# Check the updated data types of columns in df\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fb9bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(DatGan_path + folder_name)\n",
    "\n",
    "# File path where you want to save the dictionary as a JSON file\n",
    "file_path = 'data_info.json'\n",
    "\n",
    "# Save the dictionary as a JSON file\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(data_info, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f8fcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "relations = [(\"CarModelYear\", \"FuelType\"),\n",
    "    (\"Education\", \"IncRespondent2000\"),\n",
    "    (\"Education\", \"Sector\"),\n",
    "    (\"FamNumPers\", \"FamNumAdults\"),\n",
    "    (\"FamNumPers\", \"KidsBetween0and15\"),\n",
    "    (\"Gender\", \"Education\"),\n",
    "    (\"Gender\", \"IncRespondent2000\"),\n",
    "    (\"HomeAdrZone\", \"HousehAccomodation\"),\n",
    "    (\"HousehAccomodation\", \"HomeParkPoss\"),\n",
    "    (\"HousehAccomodation\", \"HousehAccOwnorRent\"),\n",
    "    (\"HousehAccomodation\", \"HousehNumPers\"),\n",
    "    (\"HousehCarOwnership\", \"CarModelYear\"),\n",
    "    (\"HousehNumAdults\", \"FamNumAdults\"),\n",
    "    (\"HousehNumPers\", \"FamNumPers\"),\n",
    "    (\"HousehNumPers\", \"HousehNumAdults\"),\n",
    "    (\"HousehNumPers\", \"HousehNumcars\"),\n",
    "    (\"HousehNumcars\", \"CarModelYear\"),\n",
    "    (\"HousehNumcars\", \"HousehCarOwnership\"),\n",
    "    (\"HwDayspW\", \"PrimModeDay\"),\n",
    "    (\"IncFamily2000\", \"HousehAccOwnorRent\"),\n",
    "    (\"IncFamily2000\", \"HousehCarOwnership\"),\n",
    "    (\"IncFamily2000\", \"IncRespondent2000\"),\n",
    "    (\"IncRespondent2000\", \"WorkHourType\"),\n",
    "    (\"KidsBetween0and15\", \"KidsBetween0and4\"),\n",
    "    (\"MunicipalityDest\", \"PrimModeDay\"),\n",
    "    (\"MunicipalityDest\", \"PrimOccZone\"),\n",
    "    (\"MunicipalityOrigin\", \"HomeAdrZone\"),\n",
    "    (\"MunicipalityOrigin\", \"Sector\"),\n",
    "    (\"PopSocio\", \"Education\"),\n",
    "    (\"PopSocio\", \"MunicipalityDest\"),\n",
    "    (\"PopSocio\", \"RespPrimOcc\"),\n",
    "    (\"PrimModeDay\", \"ModeChainTypeDay\"),\n",
    "    (\"PrimModeDay\", \"RespHasBicycle\"),\n",
    "    (\"PrimModeDay\", \"RespHasRejsekort\"),\n",
    "    (\"PrimModeDay\", \"ResphasDrivlic\"),\n",
    "    (\"RespAgeCorrect\", \"Education\"),\n",
    "    (\"RespAgeCorrect\", \"PopSocio\"),\n",
    "    (\"RespAgeCorrect\", \"PosInFamily\"),\n",
    "    (\"RespAgeCorrect\", \"ResphasDrivlic\"),\n",
    "    (\"RespHasRejsekort\", \"RespHasSeasonticket\"),\n",
    "    (\"RespPrimOcc\", \"IncRespondent2000\"),\n",
    "    (\"ResphasDrivlic\", \"RespIsmemCarshare\"),\n",
    "    (\"WorkHourType\", \"HwDayspW\"),\n",
    "    (\"WorkHourType\", \"WorkHoursPw\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9e478a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(DatGan_path + folder_name)\n",
    "\n",
    "# Convert the list of tuples to a JSON-serializable format\n",
    "serialized_relations = [list(rel) for rel in relations]\n",
    "\n",
    "# Save the data to a JSON file\n",
    "file_path = 'relations.json'  # Define the file path\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(serialized_relations, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6997b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(DatGan_path + folder_name)\n",
    "\n",
    "graph = nx.DiGraph()\n",
    "graph.add_edges_from(relations)\n",
    "graph.add_node(\"Year\")\n",
    "graph.add_node(\"Handicap\")\n",
    "nx.write_adjlist(graph, \"graph.adjlist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681ae08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(DatGan_path)\n",
    "os.chdir(folder_name)\n",
    "\n",
    "train_set = pd.read_csv('trainData.csv', sep=',', dtype=df_dtypes) # Read the training set\n",
    "train_set.drop(train_set.columns[train_set.columns.str.contains('unnamed', case=False)], axis=1, inplace=True)\n",
    "\n",
    "test_set = pd.read_csv('testData.csv', sep=',', dtype=df_dtypes) # Read the testing set\n",
    "test_set.drop(test_set.columns[test_set.columns.str.contains('unnamed', case=False)], axis=1, inplace=True)\n",
    "\n",
    "# Check the shapes of your sets\n",
    "print(\"Training set shape:\", train_set.shape)\n",
    "print(\"Testing set shape:\", test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9e656e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the categorical columns, we can simply add them using a for loop\n",
    "for c in train_set.columns:\n",
    "    if c not in data_info.keys():\n",
    "        data_info[c] = {'type': 'categorical'}\n",
    "\n",
    "# Convert columns in df according to data_info dictionary\n",
    "for column, info in data_info.items():\n",
    "    col_type = info['type']\n",
    "        \n",
    "    if col_type == 'categorical':\n",
    "        train_set[column] = train_set[column].astype('category')  # Convert to categorical dtype\n",
    "\n",
    "# Check the updated data types of columns in df\n",
    "print(train_set.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bf1f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DatGan Preprocessing of DATA input\n",
    "from datgan import DATGAN\n",
    "\n",
    "os.chdir(os.path.join(DatGan_path, folder_name, 'DatGan'))\n",
    "\n",
    "batch_size = 1116\n",
    "\n",
    "datgan = DATGAN(output='./output/',\n",
    "                batch_size=batch_size,\n",
    "                num_epochs=1000)\n",
    "\n",
    "datgan.preprocess(data=train_set,metadata=data_info,preprocessed_data_path='./encoded_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd96058",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ciDatGan Preprocessing of DATA input\n",
    "from datgan import DATGAN\n",
    "\n",
    "os.chdir(os.path.join(DatGan_path, folder_name, 'ciDatGan'))\n",
    "\n",
    "batch_size = 1116\n",
    "\n",
    "conditional_inputs = ['Gender', 'Education', 'MunicipalityOrigin']\n",
    "\n",
    "ciDatGan = DATGAN(output='./output/',\n",
    "                batch_size=batch_size,\n",
    "                num_epochs=1000,\n",
    "                conditional_inputs=conditional_inputs)\n",
    "\n",
    "ciDatGan.preprocess(train_set, data_info, preprocessed_data_path='./encoded_data/')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
